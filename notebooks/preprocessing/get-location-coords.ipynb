{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"get-location-coords.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"kQtIbvWVxkM0","cellView":"form","executionInfo":{"status":"ok","timestamp":1604577389161,"user_tz":-60,"elapsed":4201,"user":{"displayName":"Morgan Heggland","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gidniol1OemcJsZlIAGEaoYwo52fAtFOt9pRR5WYw=s64","userId":"17013853603557905659"}}},"source":["#@markdown <b>Run me to import underscore module</b><br/>   {display-mode: \"form\"}\n","#@markdown <small>Method signatures:</small><br/> \n","#@markdown <small><small>&nbsp; &nbsp; &nbsp; _(source_path, target_path)</small></small><br/>\n","#@markdown <small><small>&nbsp; &nbsp; &nbsp; _set_gh_token(token)</small></small><br/>\n","#@markdown <small><small>&nbsp; &nbsp; &nbsp; _from_gh(user_name, repo_name, release_name) &nbsp; &nbsp; &nbsp; <b>Returns:</B> dictionary of arrays { 'array_name' : np.ndarray }</small></small><br/>\n","#@markdown <small><small>&nbsp; &nbsp; &nbsp; _to_gh(user_name, repo_name, release_name, split_size=600, **arr_kwargs)</small></small><br/>\n","\n","!pip install -q githubrelease\n","import numpy as np\n","import os, glob, re, time\n","import github_release\n","\n","compressed_dirs = set()\n","\n","\n","def _compress(source_path, target_path, target_dir=None):\n","    if target_dir:\n","        !mkdir -p {target_dir}\n","    if target_path.endswith('.tar.gz'):\n","        !tar -czf {target_path} -C {source_path} .\n","    elif target_path.endswith('.tar'):\n","        !tar -cf {target_path} -C {source_path} .\n","    elif target_path.endswith('.zip'):\n","        !(cd {source_path} && zip -q -r {target_path} .)\n","\n","\n","def _extract(source_path, target_path):\n","    !mkdir -p {target_path}\n","    if source_path.endswith('.tar.gz'):\n","        !tar -xzf {source_path} -C {target_path}\n","    elif source_path.endswith('.tar'):\n","        !tar -xf {source_path} -C {target_path}\n","    elif source_path.endswith('.zip'):\n","        !unzip -qq {source_path} -d {target_path}\n","\n","\n","def _(source_path, target_path):\n","    \"\"\"\n","    Use cases:\n","        Movement:\n","            - GCS -> GCS\n","            - GCS -> LOCAL\n","            - LOCAL -> GCS\n","            - LOCAL -> LOCAL\n","            \n","        Compression (e.g. from dir to .tar.gz):\n","            - GCS -> GCS\n","            - GCS -> LOCAL\n","            - LOCAL -> GCS\n","            - LOCAL -> LOCAL\n","            \n","        Extraction (e.g. from .zip to dir):\n","            - GCS -> GCS\n","            - GCS -> LOCAL\n","            - LOCAL -> GCS\n","            - LOCAL -> LOCAL\n","            \n","        Extraction & compression (e.g. from .zip to .tar.gz):\n","            - GCS -> GCS\n","            - GCS -> LOCAL\n","            - LOCAL -> GCS\n","            - LOCAL -> LOCAL\n","    \"\"\"\n","    COMPRESSION_FORMATS = ('zip', 'tar', 'tar.gz')\n","    TEMP_DIR = \"/tmp_\"\n","    LOG_TEMPLATE = \"{}    from    {}    to    {}\"\n","\n","    # Source\n","    source_dir, _, source_name = source_path.rpartition('/')\n","    source_isgcs = source_path.startswith(\"gs://\")\n","    source_islocal = not source_isgcs\n","    source_isprefix, source_isfile, source_ext = source_name.partition('.')\n","    source_isdir = not source_isfile\n","    source_iscompression = source_ext in COMPRESSION_FORMATS\n","\n","    # Target\n","    target_dir, _, target_name = target_path.rpartition('/')\n","    target_isgcs = target_path.startswith(\"gs://\")\n","    target_islocal = not target_isgcs\n","    target_prefix, target_isfile, target_ext = target_name.partition('.')\n","    target_isdir = not target_isfile\n","    target_iscompression = target_ext in COMPRESSION_FORMATS\n","\n","    # Flags\n","    MOVE_ONLY = source_ext == target_ext\n","    GCS_ONLY = source_isgcs and target_isgcs\n","    RENAME = source_isprefix != target_prefix\n","    COMPRESSION = source_isdir and target_iscompression\n","    EXTRACTION = source_iscompression and target_isdir\n","    EXTRACTION_COMPRESSION = source_iscompression and target_iscompression and source_ext != target_ext\n","\n","    # Authenticate if writing to GCS\n","    if target_isgcs:\n","        from google.colab import auth\n","        auth.authenticate_user()\n","\n","    # Assert that subdirectories exist if target is local\n","    if target_islocal:\n","        !mkdir -p {target_dir}\n","\n","    # Movement commands\n","    if MOVE_ONLY:\n","        # GCS -> GCS\n","        if source_isgcs and target_isgcs:\n","            print(LOG_TEMPLATE.format(\"MOVING (1/1)\", source_path, target_path))\n","            !gsutil -m -q mv {source_path} {target_path}\n","        \n","        # LOCAL -> LOCAL\n","        elif source_islocal and target_islocal:\n","            print(LOG_TEMPLATE.format(\"MOVING (1/1)\", source_path, target_path))\n","            !mv {source_path} {target_path}\n","        \n","        # GCS -> LOCAL\n","        elif source_isgcs and target_islocal:\n","            if source_isdir:\n","                print(LOG_TEMPLATE.format(\"DOWNLOADING DIR (1/1)\", source_path, target_dir))\n","                !gsutil -m -q cp -r {source_path} {target_dir}\n","                if RENAME:\n","                    print(LOG_TEMPLATE.format(\"\\tRENAMING DIR\", source_isprefix, target_prefix))\n","                    !mv {target_dir}/{source_isprefix} {target_dir}/{target_prefix}\n","            else:\n","                print(LOG_TEMPLATE.format(\"DOWNLOADING FILE (1/1)\", source_path, target_path))\n","                !gsutil -m -q cp {source_path} {target_path}\n","        \n","        # LOCAL -> GCS\n","        if source_islocal and target_isgcs:\n","            if source_isdir:\n","                print(LOG_TEMPLATE.format(\"UPLOADING DIR (1/1)\", source_path, target_path))\n","                !gsutil -m -q cp -r {source_path} {target_path}\n","            else:\n","                print(LOG_TEMPLATE.format(\"UPLOADING FILE (1/1)\", source_path, target_path))\n","                !gsutil -m -q cp {source_path} {target_path}\n","        return\n","\n","\n","    # Create directory for intermediate storage if required\n","    if source_isgcs or target_isgcs or EXTRACTION_COMPRESSION:\n","        !mkdir -p {TEMP_DIR}\n","    \n","\n","    # For remaining operations, download GCS source to temp and treat as local\n","    if source_isgcs:\n","        if source_isdir:\n","            print(LOG_TEMPLATE.format(\"\\tDOWNLOADING DIR\", source_path, TEMP_DIR))\n","            !gsutil -m -q cp -r {source_path} {TEMP_DIR}\n","        else:\n","            print(LOG_TEMPLATE.format(\"\\tDOWNLOADING FILE\", source_path, f\"{TEMP_DIR}/{source_name}\"))\n","            !gsutil -m -q cp {source_path} {TEMP_DIR}/{source_name}\n","        source_path = f\"{TEMP_DIR}/{source_name}\"\n","        source_dir = TEMP_DIR\n","\n","    # Compression\n","    if COMPRESSION:\n","        if target_islocal:\n","            print(LOG_TEMPLATE.format(\"COMPRESSING (1/1)\", source_path, target_path))\n","            _compress(source_path, target_path, target_dir=target_dir)\n","        else:\n","            print(LOG_TEMPLATE.format(\"COMPRESSING (1/2)\", source_path, f\"{TEMP_DIR}/{target_name}\"))\n","            _compress(source_path, f\"{TEMP_DIR}/{target_name}\")\n","            print(LOG_TEMPLATE.format(\"UPLOADING FILE (2/2)\", f\"{TEMP_DIR}/{target_name}\", target_path))\n","            !gsutil -m -q cp {TEMP_DIR}/{target_name} {target_path}\n","\n","    # Extraction\n","    elif EXTRACTION:\n","        if target_islocal:\n","            print(LOG_TEMPLATE.format(\"EXTRACTING (1/1)\", source_path, target_path))\n","            _extract(source_path, target_path)\n","        else:\n","            print(LOG_TEMPLATE.format(\"EXTRACTING (1/2)\", source_path, f\"{TEMP_DIR}/{target_name}\"))\n","            _extract(source_path, f\"{TEMP_DIR}/{target_name}\")\n","            print(LOG_TEMPLATE.format(\"UPLOADING DIR (2/2)\", f\"{TEMP_DIR}/{target_name}\", target_path))\n","            !gsutil -m -q cp -r {TEMP_DIR}/{target_name} {target_path}\n","\n","    # Extraction & compression\n","    elif EXTRACTION_COMPRESSION:\n","        if target_islocal:\n","            print(LOG_TEMPLATE.format(\"EXTRACTING (1/2)\", source_path, f\"{TEMP_DIR}/{target_prefix}\"))\n","            _extract(source_path, f\"{TEMP_DIR}/{target_prefix}\")\n","            print(LOG_TEMPLATE.format(\"COMPRESSING (2/2)\", f\"{TEMP_DIR}/{target_prefix}\", target_path))\n","            _compress(f\"{TEMP_DIR}/{target_prefix}\", target_path, target_dir=target_dir)\n","        else:\n","            print(LOG_TEMPLATE.format(\"EXTRACTING (1/3)\", source_path, f\"{TEMP_DIR}/{target_prefix}\"))\n","            _extract(source_path, f\"{TEMP_DIR}/{target_prefix}\")\n","            print(LOG_TEMPLATE.format(\"COMPRESSING (2/3)\", f\"{TEMP_DIR}/{target_prefix}\", f\"{TEMP_DIR}/{target_name}\"))\n","            _compress(f\"{TEMP_DIR}/{target_prefix}\", f\"{TEMP_DIR}/{target_name}\")\n","            print(LOG_TEMPLATE.format(\"UPLOADING FILE (3/3)\", f\"{TEMP_DIR}/{target_name}\", target_path))\n","            !gsutil -m -q cp {TEMP_DIR}/{target_name} {target_path}\n","    \n","    # Cleanup intermediate storage\n","    !rm -rf {TEMP_DIR}\n","\n","\n","def _set_gh_token(token):\n","    os.environ[\"GITHUB_TOKEN\"] = token\n","\n","\n","def _export_array(array, release_name, prefix=\"\", splits=3):\n","    dir_path = f\"/tmp_/{release_name}\"\n","    !mkdir -p {dir_path}\n","    n_digits = len(str(splits - 1))\n","    subarrays = np.array_split(array, splits)\n","    for i, subarray in enumerate(subarrays):\n","        filename = f\"{prefix}__{str(i).zfill(n_digits)}.npy\"\n","        np.save(f\"{dir_path}/{filename}\", subarray)\n","\n","\n","def _concat_arrays(paths):\n","    return np.concatenate([np.load(path, allow_pickle=True) for path in sorted(paths)])\n","\n","\n","def _to_gh(user_name, repo_name, release_name, split_size=600, **arr_kwargs):\n","    # Assert that GitHub Auth token is set\n","    if \"GITHUB_TOKEN\" not in os.environ:\n","        print(\"GitHub authentication token is not set.\")\n","        print(\"Set token using the '_set_gh_token(token_string)' method.\")\n","        print(\"Minimal required auth scope is 'repo/public_repo' for public repositories.\")\n","        print(\"URL: https://github.com/settings/tokens/new\")\n","        return\n","\n","    # Split arrays\n","    for prefix, array in arr_kwargs.items():\n","        splits = int((array.nbytes/1_000_000) // split_size) + 1\n","        _export_array(array, release_name, prefix=prefix, splits=splits)\n","\n","    # Upload arrays\n","    github_release.gh_release_create(\n","        f\"{user_name}/{repo_name}\", \n","        release_name, \n","        publish=True, \n","        name=release_name, \n","        asset_pattern=f\"/tmp_/{release_name}/*\"\n","    )\n","    !rm -rf /tmp_/*\n","\n","\n","def _from_gh(user_name, repo_name, release_name):\n","    # Download release to temporary directory\n","    print(\"Downloading dataset in parallell ... \", end='\\t')\n","    t0 = time.perf_counter()\n","    assets = github_release.get_assets(f\"{user_name}/{repo_name}\", tag_name=release_name)\n","    download_urls = [asset['browser_download_url'] for asset in assets]\n","    urls_str = \" \".join(download_urls)\n","    !echo {urls_str} | xargs -n 1 -P 8 wget -q -P /tmp_/{release_name}_dl/\n","    t1 = time.perf_counter()\n","    print(f\"done! ({t1 - t0:.3f} seconds)\")\n","\n","    # Load data into numpy arrays\n","    paths = glob.glob(f\"/tmp_/{release_name}_dl/*.npy\")\n","    groups = {}\n","    for path in paths:\n","        match = re.match(r\".*/(.*)__[0-9]*\\.npy\", path)\n","        if match:\n","            prefix = match.group(1)\n","            groups[prefix] = groups.get(prefix, []) + [path]\n","    arrays_dict = {name: _concat_arrays(paths) for name, paths in groups.items()}\n","    !rm -rf /tmp_/*\n","    return arrays_dict\n","    \n","\n","def _log_to_gh(user, repo, tag, log_dir=\"/tmp/logs\"):\n","    # Create temporary directory for compressed logs\n","    !mkdir -p /tmp/compressed_logs\n","    \n","    # Compress all directories in log dir\n","    for dirname in os.listdir(log_dir):\n","        # Skip files\n","        if \".\" in dirname or dirname in compressed_dirs:\n","            continue\n","\n","        # Compress\n","        _(f\"{log_dir}/{dirname}\", f\"/tmp/compressed_logs/{dirname}.tar.gz\")\n","        compressed_dirs.add(dirname)\n","\n","    # Upload compressed logs to GitHub\n","    github_release.gh_asset_upload(f\"{user}/{repo}\", tag, f\"/tmp/compressed_logs/*.tar.gz\")\n","\n","    # Cleanup compressed logs\n","    !rm -rf /tmp/compressed_logs/*"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"V5NQXbfo-zjp","executionInfo":{"status":"ok","timestamp":1604575355069,"user_tz":-60,"elapsed":2688,"user":{"displayName":"Morgan Heggland","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gidniol1OemcJsZlIAGEaoYwo52fAtFOt9pRR5WYw=s64","userId":"17013853603557905659"}}},"source":["import glob\n","import os\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"vVPknc87--MY","executionInfo":{"status":"ok","timestamp":1604575355070,"user_tz":-60,"elapsed":1403,"user":{"displayName":"Morgan Heggland","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gidniol1OemcJsZlIAGEaoYwo52fAtFOt9pRR5WYw=s64","userId":"17013853603557905659"}}},"source":["# Project info\n","PROJECT_ID = 'telenor-data-science'\n","DATASET = \"raw/raw_dataset_separate_providers.zip\"\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UpYxAh81zEs","executionInfo":{"status":"ok","timestamp":1604575437927,"user_tz":-60,"elapsed":81808,"user":{"displayName":"Morgan Heggland","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gidniol1OemcJsZlIAGEaoYwo52fAtFOt9pRR5WYw=s64","userId":"17013853603557905659"}},"outputId":"ebad5835-cfe5-4323-d427-6ec385c4c18c","colab":{"base_uri":"https://localhost:8080/"}},"source":["_(f\"gs://{PROJECT_ID}/datasets/{DATASET}\",\"/content/data_separate\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\tDOWNLOADING FILE    from    gs://telenor-data-science/datasets/raw/raw_dataset_separate_providers.zip    to    /tmp_/raw_dataset_separate_providers.zip\n","EXTRACTING (1/1)    from    /tmp_/raw_dataset_separate_providers.zip    to    /content/data_separate\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EVzBp_h08VYU","executionInfo":{"status":"ok","timestamp":1604575443682,"user_tz":-60,"elapsed":2037,"user":{"displayName":"Morgan Heggland","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gidniol1OemcJsZlIAGEaoYwo52fAtFOt9pRR5WYw=s64","userId":"17013853603557905659"}},"outputId":"cbb8e0ea-398b-4647-ba11-ee9ab61e0271","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["locations = pd.DataFrame(columns=[\"location\", \"Latitude\", \"Longitude\"])\n","\n","paths = glob.glob(\"/content/data_separate/data-dump/NEA/*\", recursive=True)\n","\n","for path in paths:\n","    dir_name, sep, location = path.rpartition(os.sep)\n","    df = pd.read_parquet(f\"/content/data_separate/data-dump/NEA/{location}/2020/2020.parquet\")\n","    station = df['station'][0]\n","    lat = df['lat'][0]\n","    lon = df['lon'][0]\n","    row = pd.DataFrame([[station, lat, lon]], columns=[\"location\", \"Latitude\", \"Longitude\"])\n","    locations = locations.append(row, ignore_index=True)\n","\n","locations"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>location</th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Våland</td>\n","      <td>58.961730</td>\n","      <td>5.731470</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hansjordnesbukta</td>\n","      <td>69.656250</td>\n","      <td>18.963720</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Knarrdalstranda</td>\n","      <td>59.133540</td>\n","      <td>9.621900</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Nygaardsgata</td>\n","      <td>59.210191</td>\n","      <td>10.940097</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Solheim</td>\n","      <td>59.928612</td>\n","      <td>10.953203</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Moheia Vest</td>\n","      <td>66.312191</td>\n","      <td>14.149923</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Kannik</td>\n","      <td>58.964150</td>\n","      <td>5.727850</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>E6 Alna senter</td>\n","      <td>59.925560</td>\n","      <td>10.850367</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Bekkestua</td>\n","      <td>59.918100</td>\n","      <td>10.583900</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>E6-Tiller</td>\n","      <td>63.357600</td>\n","      <td>10.371900</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Rolland, Åsane</td>\n","      <td>60.462665</td>\n","      <td>5.332447</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Bankplassen</td>\n","      <td>61.112880</td>\n","      <td>10.464970</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Bygdøy Alle</td>\n","      <td>59.918980</td>\n","      <td>10.697070</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Vangsveien, Hamar</td>\n","      <td>60.796460</td>\n","      <td>11.097770</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Olav V gate</td>\n","      <td>67.275501</td>\n","      <td>14.419057</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Leiret</td>\n","      <td>60.883643</td>\n","      <td>11.559301</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Minnesundvegen, Gjøvik</td>\n","      <td>60.790890</td>\n","      <td>10.696700</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Kirkeveien</td>\n","      <td>59.932330</td>\n","      <td>10.724470</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Klosterhaugen</td>\n","      <td>60.395929</td>\n","      <td>5.312674</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Alnabru</td>\n","      <td>59.927730</td>\n","      <td>10.846330</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Bakke kirke</td>\n","      <td>63.432930</td>\n","      <td>10.410670</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Seljestad Rv83</td>\n","      <td>68.792227</td>\n","      <td>16.537423</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Hjortnes</td>\n","      <td>59.911320</td>\n","      <td>10.704070</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Bryn skole</td>\n","      <td>59.914106</td>\n","      <td>10.822630</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Elgeseter</td>\n","      <td>63.419239</td>\n","      <td>10.395945</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>Lensmannsdalen</td>\n","      <td>59.159270</td>\n","      <td>9.635650</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Eilif Dues vei</td>\n","      <td>59.906080</td>\n","      <td>10.611950</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>Danmarks plass</td>\n","      <td>60.374080</td>\n","      <td>5.340420</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>Ringsakervegen</td>\n","      <td>60.885930</td>\n","      <td>10.937850</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Alvim</td>\n","      <td>59.273775</td>\n","      <td>11.089190</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Rådal</td>\n","      <td>60.294268</td>\n","      <td>5.324619</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Torvet</td>\n","      <td>63.430380</td>\n","      <td>10.393550</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>Loddefjord</td>\n","      <td>60.361135</td>\n","      <td>5.236860</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>Sofienbergparken</td>\n","      <td>59.922950</td>\n","      <td>10.765730</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>Rv 4, Aker sykehus</td>\n","      <td>59.941030</td>\n","      <td>10.798030</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Vigernes</td>\n","      <td>59.955477</td>\n","      <td>11.073983</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>Smestad</td>\n","      <td>59.932550</td>\n","      <td>10.669840</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>St.Croix</td>\n","      <td>59.210300</td>\n","      <td>10.945400</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>Nedre Langgate</td>\n","      <td>59.263725</td>\n","      <td>10.411165</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>Furulund</td>\n","      <td>59.057304</td>\n","      <td>9.695568</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>Lillehammer barnehage</td>\n","      <td>61.120870</td>\n","      <td>10.465630</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>Manglerud</td>\n","      <td>59.898690</td>\n","      <td>10.814950</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>Schancheholen</td>\n","      <td>58.951877</td>\n","      <td>5.721875</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>Kransen</td>\n","      <td>59.433471</td>\n","      <td>10.661762</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  location   Latitude  Longitude\n","0                   Våland  58.961730   5.731470\n","1         Hansjordnesbukta  69.656250  18.963720\n","2          Knarrdalstranda  59.133540   9.621900\n","3             Nygaardsgata  59.210191  10.940097\n","4                  Solheim  59.928612  10.953203\n","5              Moheia Vest  66.312191  14.149923\n","6                   Kannik  58.964150   5.727850\n","7           E6 Alna senter  59.925560  10.850367\n","8                Bekkestua  59.918100  10.583900\n","9                E6-Tiller  63.357600  10.371900\n","10          Rolland, Åsane  60.462665   5.332447\n","11             Bankplassen  61.112880  10.464970\n","12             Bygdøy Alle  59.918980  10.697070\n","13       Vangsveien, Hamar  60.796460  11.097770\n","14             Olav V gate  67.275501  14.419057\n","15                  Leiret  60.883643  11.559301\n","16  Minnesundvegen, Gjøvik  60.790890  10.696700\n","17              Kirkeveien  59.932330  10.724470\n","18           Klosterhaugen  60.395929   5.312674\n","19                 Alnabru  59.927730  10.846330\n","20             Bakke kirke  63.432930  10.410670\n","21          Seljestad Rv83  68.792227  16.537423\n","22                Hjortnes  59.911320  10.704070\n","23              Bryn skole  59.914106  10.822630\n","24               Elgeseter  63.419239  10.395945\n","25          Lensmannsdalen  59.159270   9.635650\n","26          Eilif Dues vei  59.906080  10.611950\n","27          Danmarks plass  60.374080   5.340420\n","28          Ringsakervegen  60.885930  10.937850\n","29                   Alvim  59.273775  11.089190\n","30                   Rådal  60.294268   5.324619\n","31                  Torvet  63.430380  10.393550\n","32              Loddefjord  60.361135   5.236860\n","33        Sofienbergparken  59.922950  10.765730\n","34      Rv 4, Aker sykehus  59.941030  10.798030\n","35                Vigernes  59.955477  11.073983\n","36                 Smestad  59.932550  10.669840\n","37                St.Croix  59.210300  10.945400\n","38          Nedre Langgate  59.263725  10.411165\n","39                Furulund  59.057304   9.695568\n","40   Lillehammer barnehage  61.120870  10.465630\n","41               Manglerud  59.898690  10.814950\n","42           Schancheholen  58.951877   5.721875\n","43                 Kransen  59.433471  10.661762"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"Bi7MfSXk9fsj","executionInfo":{"status":"ok","timestamp":1604575464514,"user_tz":-60,"elapsed":914,"user":{"displayName":"Morgan Heggland","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gidniol1OemcJsZlIAGEaoYwo52fAtFOt9pRR5WYw=s64","userId":"17013853603557905659"}}},"source":["locations.to_csv(\"/content/locations.csv\", index=False)"],"execution_count":6,"outputs":[]}]}