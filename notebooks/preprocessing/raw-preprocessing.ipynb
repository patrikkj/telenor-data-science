{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"raw-preprocessing.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMkPGsRcBUVMQxte0F3PZhF"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XzSuSCgdVPaD"},"source":["### Link to Google Drive: https://drive.google.com/drive/folders/1Pnuo1tB1XtiDjMa7eXmuUctL2XX9emU7\n","### Link to Tableau Online: https://dub01.online.tableau.com/#/site/telenordashboard/projects/123532\n","### Link to Google Cloud Storage: https://console.cloud.google.com/storage/browser?project=telenor-data-science\n","### Link to Google Cloud BigQuery: https://console.cloud.google.com/bigquery?project=telenor-data-science&p=telenor-data-science&d=telenor_dataset&page=dataset"]},{"cell_type":"code","metadata":{"id":"MSnRVwRihC_N"},"source":["import glob\n","import os\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rfOfPrlAWflD"},"source":["# Project info\n","PROJECT_ID = 'telenor-data-science'\n","DATASET = 'raw_dataset_joined.tar.gz'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JsYusB9hgzpG","cellView":"code"},"source":["# Download dataset from GCS\n","!gsutil -q cp gs://{PROJECT_ID}/datasets/{DATASET} /tmp\n","!mkdir -p data\n","!tar -zxf /tmp/{DATASET} -C /content/data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJ7uL483jaAE"},"source":["paths = glob.glob(\"/content/data/**/*.parquet\", recursive=True)\n","dataframes = {}\n","\n","# Load all parquet files as dataframes\n","for path in paths:\n","    df = pd.read_parquet(path)\n","    dir_name = path.split(os.sep)[-2]\n","    df_tuple = (df, os.path.splitext(path)[0][-4:])\n","    df_old = dataframes.get(dir_name, [])\n","    df_old.append(df_tuple)\n","    dataframes[dir_name] = df_old\n","\n","# Create mapping {location -> [[df1, df2, df3, ...], [year1, year2, year3, ...]]}\n","for k, v in dataframes.items():\n","    dataframes[k] = list(zip(*v))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhReeIJLpFNI","executionInfo":{"status":"ok","timestamp":1602882806665,"user_tz":-120,"elapsed":5343,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"17621156606987172084"}},"outputId":"eccb6988-b0cb-4c7a-9f19-57866c7b31dc","colab":{"base_uri":"https://localhost:8080/","height":788}},"source":["# Print years and number of features\n","template = \"{:20}\\t{:>10}\\t{}\"\n","print(template.format(\"Location\", \"# columns\", \"Years\"))\n","for location, data in dataframes.items():\n","    dfs, years = data\n","    years = ', '.join(sorted(years))\n","\n","     # Count number of unique columns\n","    location_columns = set()\n","    for df in dfs:\n","        location_columns.update(df.columns)\n","    num_of_columns = len(location_columns)\n","    print(template.format(location, num_of_columns, years))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Location            \t # columns\tYears\n","E6-Tiller           \t        45\t2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Alvim               \t        41\t2015, 2016, 2017, 2018, 2019, 2020\n","Sofienbergparken    \t        58\t2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Manglerud           \t       104\t2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Leiret              \t        54\t2016, 2017, 2018, 2019, 2020\n","Minnesundvegen, Gjøvik\t        42\t2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Vangsveien, Hamar   \t        43\t2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Rv 4, Aker sykehus  \t       106\t2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Ringsakervegen      \t        30\t2018, 2019, 2020\n","Bakke kirke         \t        50\t2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Moheia Vest         \t        17\t2018, 2019, 2020\n","Torvet              \t        64\t2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Klosterhaugen       \t       125\t2017, 2018, 2019, 2020\n","Hansjordnesbukta    \t        47\t2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Nygaardsgata        \t        47\t2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Hjortnes            \t        41\t2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Schancheholen       \t        90\t2018, 2019, 2020\n","St.Croix            \t        30\t2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Bankplassen         \t        30\t2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Kransen             \t        54\t2011, 2012, 2015, 2016, 2017, 2018, 2019, 2020\n","Solheim             \t        67\t2017, 2018, 2019, 2020\n","Knarrdalstranda     \t        28\t2017, 2018, 2019, 2020\n","Furulund            \t        34\t2016, 2017, 2018, 2019, 2020\n","Våland             \t        74\t2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Bryn skole          \t        91\t2018, 2019, 2020\n","Alnabru             \t        92\t2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Olav V gate         \t        41\t2018, 2019, 2020\n","Loddefjord          \t       121\t2015, 2016, 2017, 2018, 2019, 2020\n","Elgeseter           \t        46\t2000, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Rolland, Åsane     \t        58\t2015, 2016, 2017, 2018, 2019, 2020\n","Kannik              \t        92\t1996, 1997, 1999, 2000, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Nedre Langgate      \t        54\t2018, 2019, 2020\n","Vigernes            \t        30\t2015, 2016, 2017, 2018, 2019, 2020\n","Kirkeveien          \t        47\t1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Lensmannsdalen      \t        47\t2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Danmarks plass      \t       120\t2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Bygdøy Alle         \t        36\t2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Lillehammer barnehage\t        36\t2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Bekkestua           \t        52\t2016, 2017, 2018, 2019, 2020\n","E6 Alna senter      \t        50\t2017, 2018, 2019, 2020\n","Seljestad Rv83      \t        48\t2018, 2019, 2020\n","Smestad             \t        59\t2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Eilif Dues vei      \t        51\t2014, 2015, 2016, 2017, 2018, 2019, 2020\n","Rådal              \t        36\t2017, 2018, 2019, 2020\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1pmU3MKkFCFB"},"source":["'''\n","def rename_col(name):\n","    \"\"\"Conversion to make column names compatible with BigQuery.\"\"\"\n","    problematic_chars = ' .,:;{}()='\n","    for c in problematic_chars:\n","        name = name.replace(c, '_')\n","    return name\n","'''\n","\n","import re\n","def rename_col(name):\n","    \"\"\"Conversion to make column names compatible with BigQuery.\"\"\"\n","    name = re.sub(\"(PRA\\.(.+)\\.(.+)\\.(.+))\", r'PRA_\\3__\\4', name)\n","    name = re.sub(\"(MET\\.[a-zA-Z0-9]*:0\\.)\", r'MET_', name)\n","    name = re.sub(r\"(NEA\\..*\\.(NOx|PM2_5|PM10|NO2|PM1|NO))\", r'NEA_\\2', name)\n","    name = re.sub(r\"(Kystverket\\.[a-zA-Z0-9_-]*\\.(stationary|moving))\", r'KV_\\2', name)\n","    return name\n","\n","def rename_file(name):\n","    name = name.lower()\n","    for c in \" ,.-:;{}[]()=\":\n","        name = name.replace(c, '_')\n","    return name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dH681J9hr0JB"},"source":["base_dfs = []\n","\n","for location, lists in dataframes.items():\n","    dfs, years = lists\n","    dfs = list(dfs)\n","    # Rename all columns (Thanks telenor :))\n","    for i, df in enumerate(dfs):\n","        translation = {col: rename_col(col) for col in df.columns}\n","        dfs[i] = df.rename(columns=translation)\n","\n","    # Create new root dataframe for directory\n","    base_df = pd.DataFrame()\n","\n","    # Add location and years data to dataframe\n","    base_df['year'] = None\n","    \n","    # Identify all unique columns\n","    location_columns = set()\n","    for df in dfs:\n","        location_columns.update(df.columns)\n","    \n","    # Generate colummns in base dataframe\n","    for column_name in location_columns:\n","        base_df[column_name] = None\n","\n","    # Add all rows of data to base dataframe\n","    for df, year in zip(dfs, years):\n","        df['year'] = year\n","        base_df = base_df.append(df)\n","    \n","    # Add location to all rows\n","    base_df.insert(1, 'location', location)\n","    base_df = base_df.reindex(sorted(base_df.columns), axis=1)\n","    base_dfs.append(base_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XS6ID2cgN-uq","executionInfo":{"status":"ok","timestamp":1602882930865,"user_tz":-120,"elapsed":537,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"17621156606987172084"}},"outputId":"654cf956-4d3f-43b2-9391-5e4a7455ef29","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Total number of rows in all datasets\n","import numpy as np\n","print(np.array([df.shape for df in base_dfs]).sum(axis=0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[3700794    2557]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SfCwFZHSHqoV"},"source":["# Export .parquet files to local storage\n","for location, base_df in zip(dataframes.keys(), base_dfs):\n","    print(base_df.columns)\n","    filename = rename_file(location)\n","    print(f\"Exporting {filename} ...\") \n","    for col in columns:\n","        print(f\"    {col}\")\n","    !mkdir -p /tmp/location_dataset\n","    base_df.to_parquet(f\"/tmp/location_dataset/{filename}.parquet\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGTI9KzC9ZAj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eoeb751R31fs"},"source":["# Upload dataset to Google Cloud Storage\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","FROM = \"/tmp/location_dataset\"\n","TO = \"gs://telenor-data-science/datasets/location_dataset\"\n","IS_DIR = True\n","\n","if IS_DIR:\n","    !gsutil -m cp -r {FROM} {TO}\n","else:\n","    !gsutil cp {FROM} {TO}\n","\n","# Compress and upload compresed version to GCS\n","!tar -czvf /tmp/location_dataset.tar.gz /tmp/location_dataset\n","!gsutil cp /tmp/location_dataset.tar.gz gs://telenor-data-science/datasets/location_dataset.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"srB5DKIalZRZ","executionInfo":{"status":"ok","timestamp":1602889452521,"user_tz":-120,"elapsed":12525,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"17621156606987172084"}},"outputId":"b7e34c15-e303-44bc-a751-736e29bfe381","colab":{"base_uri":"https://localhost:8080/","height":154}},"source":["# DOESNT WORK - Type conflict on parquet inferred schema vs. df index :( \n","#root_df = pd.DataFrame()\n","root_df = base_dfs[0].copy().iloc[0:0]\n","#root_df = root_df.set_index(base_dfs[0].iloc[0:0].index)\n","# Identify all unique columns\n","root_columns = set()\n","for df in base_dfs:\n","    root_columns.update(df.columns)\n","\n","# Generate colummns in root dataframe\n","for column_name in root_columns:\n","    root_df[column_name] = ''\n","\n","# Rearrange columns\n","root_df = root_df.reindex(sorted(root_df.columns), axis=1)\n","\n","#Change col types\n","#root_df.append(base_dfs[0])\n","#root_df = root_df.iloc[0:0]\n","root_df = root_df.astype(float)\n","root_df = root_df.astype({'year': 'str', 'location': 'str'})\n","\n","root_df.to_parquet(f\"/tmp/location_dataset/all_locations.parquet\")\n","!gsutil cp /tmp/location_dataset/all_locations.parquet gs://telenor-data-science/datasets/location_dataset/all_locations.parquet\n","# Create table\n","!bq load --source_format=PARQUET --ignore_unknown_values --autodetect telenor-data-science:location_dataset.all_locations gs://telenor-data-science/datasets/location_dataset/*.parquet "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Copying file:///tmp/location_dataset/all_locations.parquet [Content-Type=application/octet-stream]...\n","/ [0 files][    0.0 B/ 38.7 KiB]                                                \r/ [1 files][ 38.7 KiB/ 38.7 KiB]                                                \r\n","Operation completed over 1 objects/38.7 KiB.                                     \n","Waiting on bqjob_r1b00740624a4021c_0000017533a7e616_1 ... (6s) Current status: DONE   \n","BigQuery error in load operation: Error processing job 'telenor-data-\n","science:bqjob_r1b00740624a4021c_0000017533a7e616_1': Error while reading data,\n","error message: incompatible types for field 'year': INT32 in Parquet vs. string\n","in schema\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x716PjHhma1l","executionInfo":{"status":"ok","timestamp":1602889349471,"user_tz":-120,"elapsed":606,"user":{"displayName":"Patrik Kjærran","photoUrl":"","userId":"17621156606987172084"}},"outputId":"025d7c62-8cfa-421d-f401-7ecc789d8e61","colab":{"base_uri":"https://localhost:8080/","height":223}},"source":["root_df.dtypes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["KV_moving_0m_to_100m          float64\n","KV_moving_10000m_to_30000m    float64\n","KV_moving_1000m_to_3000m      float64\n","KV_moving_100m_to_300m        float64\n","KV_moving_3000m_to_10000m     float64\n","                               ...   \n","PRA_9__from5_6To7_6           float64\n","PRA_9__from7_6To12_5          float64\n","PRA_9__upTo5_6                float64\n","location                       object\n","year                           object\n","Length: 141, dtype: object"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"1_ubtaEbmc5h"},"source":[""],"execution_count":null,"outputs":[]}]}